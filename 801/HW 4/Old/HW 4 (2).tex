\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,bm,fullpage}

\newcommand{\x}{\bm{x}}
\renewcommand{\a}{\bm{a}}
\renewcommand{\b}{\bm{b}}
\renewcommand{\u}{\bm{u}}
\renewcommand{\v}{\bm{v}}
\newcommand{\R}{{\mathbb R}}
\newcommand{\zero}{\bm{0}}

\title{Chase Joyner}
\author{801 Homework 4}
\date{October 15, 2015}

\begin{document}
\maketitle
\section*{Problem 1:}  (a)  Show that the $F$ test developed in the first part of this section is equivalent to the (generalized) likelihood ratio test for the reduced versus full models.  (b)  Find an $F$ test for $H_0\colon X\beta = X\beta_0$ where $\beta_0$ is known.  (c)  Construct a full versus reduced model test when $\sigma^2$ has a known value $\sigma_0^2$.
\begin{itemize}
\item[] {\bf Solution:}  (a)  Let the full model be $Y = X\beta + \epsilon$ and the reduced model be $Y = X_0\gamma + \epsilon$, where $\epsilon \sim N(0,\sigma^2I)$.  Denote the likelihood under the full model $L_F$ and the likelihood under the reduced model $L_R$.  Then, the likelihood ratio is
\[
r = \frac{\sup L_R(\sigma^2,\gamma)}{\sup L_F(\sigma^2,\beta)} = \frac{(\widehat{\sigma}^2_R)^{-n/2}\exp\{-(Y-X_0\widehat{\gamma})'(Y-X_0\widehat{\gamma})/2\widehat{\sigma}^2_R\}}{(\widehat{\sigma}^2_F)^{-n/2}\exp\{-(Y-X\widehat{\beta})'(Y-X\widehat{\beta})/2\widehat{\sigma}^2_F\}}.
\]
First, note that the estimates for $\sigma^2$ under the full and reduced model is the MSE under those models, i.e.
\[
\widehat{\sigma}^2_R = \frac{Y'(I-M_0)Y}{n} \hspace{5mm}\text{and}\hspace{5mm} \widehat{\sigma}^2_F = \frac{Y'(I-M)Y}{n}.
\]
Then, we see that we can rewrite the exponentials as
\begin{align*}
\exp\{-(Y-X_0\widehat{\gamma})'(Y-X_0\widehat{\gamma})/2\widehat{\sigma}^2_R\} &= \exp\bigg{\{}-\frac{n}{2}\cdot\frac{(Y-M_0Y)'(Y-M_0Y)}{Y'(I-M_0)Y} \bigg{\}} \\
&= \exp\bigg{\{}-\frac{n}{2}\cdot\frac{Y'Y - Y'M_0Y}{Y'Y-Y'M_0Y} \bigg{\}} \\
&= \exp\bigg{\{} -\frac{n}{2} \bigg{\}}.
\end{align*}
and
\[
\exp\{-(Y-X\widehat{\beta})'(Y-X\widehat{\beta})/2\widehat{\sigma}^2_F\} = \exp\bigg{\{} -\frac{n}{2}\bigg{\}}.
\]
Therefore, the ratio becomes 
\begin{align*}
r &= \left(\frac{\widehat{\sigma}^2_R}{\widehat{\sigma}^2_F}\right)^{-n/2} = \left( \frac{Y'(I-M_0)Y}{Y'(I-M)Y} \right)^{-n/2}.
\end{align*}
Recall the $F$ statistic is
\[
F = \frac{Y'(M-M_0)Y/r(M-M_0)}{Y'(I-M)Y/r(I-M)}.
\]
Therefore, we see the two test tests are equivalent. \\
(c)  Recall from section 2.6 that
\[
\frac{Y'(I-M)Y}{\sigma^2} \sim \chi^2\big{(}r(I-M)\big{)}.
\]
Then, under $H_0$, we calculate the test statistic
\[
\chi^2_0 = \frac{Y'(I-M)Y}{\sigma_0^2}.
\]
Therefore, reject $H_0$ if $\chi^2_0 < \chi^2\big{(}\alpha, r(I-M)\big{)}$ or if $\chi^2_0 > \chi^2\big{(}1-\alpha, r(I-M)\big{)}$. 
\end{itemize}

\section*{Problem 2:}  Redo the tests in Exercise 2.2 using the theory of Section 3.2.  Write down the models and explain the procedure.  {\bf Exercise 2.2:}  Let $y_{11},y_{12},...,y_{1r}$ be $N(\mu_1,\sigma^2)$ and $y_{21},y_{22},...,y_{2s}$ be $N(\mu_2,\sigma^2)$ with all $y_{ij}$'s independent.  Write this as a linear model.  Find estimates of $\mu_1,\mu_2,\mu_1-\mu_2$, and $\sigma^2$.  Form an $\alpha = .01$ test for $H_0\colon \mu_1 = \mu_2$.  Similarly, form 95$\%$ confidence intervals for $\mu_1-\mu_2$ and $\mu_1$.  What is the test for $H_0\colon\mu_1 = \mu_2 + \Delta$, where $\Delta$ is some known fixed quantity?  How do these results compare with the usual analysis for two independent samples?
\begin{itemize}
\item[] {\bf Solution:}
\end{itemize}

\section*{Problem 3:}  Redo the tests in Exercise 2.3 using the procedures of Section 3.2.  Write down the models and explain the procedure.  Hints:  (a) Let $A$ be a matrix of zeros, the generalized inverse of $A$, $A^-$, can be anything at all because $AA^-A = A$ for any choice of $A^-$.  (b) There is no reason why $X_0$ cannot be a matrix of zeros.  {\bf Exercise 2.3:}  Let $y_1,...,y_n$ be independent $N(\mu,\sigma^2)$.  Write a linear model for these data.  Form an $\alpha = .01$ test for $H_0\colon \mu=\mu_0$, where $\mu_0$ is some known fixed number and form a 95$\%$ confidence interval for $\mu$.  How do these results compare with the usual analysis for one sample?
\begin{itemize}
\item[] {\bf Solution:}
\end{itemize}

\section*{Problem 4:}  Show that $\beta'X'M_{MP}X\beta = 0$ if and only if $\Lambda'\beta = 0$.
\begin{itemize}
\item[] {\bf Solution:}
\end{itemize}

\section*{Problem 5:}  Consider a set of seemingly unrelated regression equations
\[
Y_i = X_i\beta_i + e_i, \hspace{5mm} e_i\sim N(0,\sigma^2I),
\]
$i = 1,...,r,$ where $X_i$ is an $n_i\times p$ matrix and the $e_i$s are independent.  Find the test for $H_0\colon \beta_1=...=\beta_r$.
\begin{itemize}
\item[] {\bf Solution:}
\end{itemize}

\end{document}
